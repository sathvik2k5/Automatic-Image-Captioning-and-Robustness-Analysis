{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T10:53:00.701886Z",
     "iopub.status.busy": "2025-04-14T10:53:00.701312Z",
     "iopub.status.idle": "2025-04-14T10:53:39.164094Z",
     "shell.execute_reply": "2025-04-14T10:53:39.163344Z",
     "shell.execute_reply.started": "2025-04-14T10:53:00.701867Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 10:53:22.294985: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744628002.696424      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744628002.814967      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `load_and_process_csv_data`\n",
    "\n",
    "Processes two CSV files (Custom and SmolVLM captions) into a unified dataset.\n",
    "\n",
    "#### **Inputs**:\n",
    "- `custom_model_file`: Path to custom model CSV.\n",
    "- `smolvlm_file`: Path to SmolVLM CSV.\n",
    "\n",
    "#### **Outputs**:\n",
    "- Returns a `DataFrame` with:\n",
    "  - `image_id`, `occlusion_level`, `original_caption`, `generated_caption`, `model_name`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T10:53:39.166023Z",
     "iopub.status.busy": "2025-04-14T10:53:39.165573Z",
     "iopub.status.idle": "2025-04-14T10:53:39.174843Z",
     "shell.execute_reply": "2025-04-14T10:53:39.173990Z",
     "shell.execute_reply.started": "2025-04-14T10:53:39.166001Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_and_process_csv_data(custom_model_file, smolvlm_file):\n",
    "\n",
    "    custom_df = pd.read_csv(custom_model_file)\n",
    "    smolvlm_df = pd.read_csv(smolvlm_file)\n",
    "    \n",
    "    def extract_caption(text):\n",
    "        match = re.search(r\"Assistant:(.*?)($|\\n)\", text, re.DOTALL)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "        return text\n",
    "    \n",
    "    smolvlm_df['caption'] = smolvlm_df['smolvlm_caption'].apply(extract_caption)\n",
    "    \n",
    "    smolvlm_df = smolvlm_df[['filename', 'occlusion_level', 'caption']]\n",
    "    custom_df = custom_df[['filename', 'occlusion_level', 'predicted_caption', 'reference_caption']]\n",
    "    \n",
    "    smolvlm_df = smolvlm_df.rename(columns={'caption': 'smolvlm_caption'})\n",
    "    custom_df = custom_df.rename(columns={'predicted_caption': 'custom_caption'})\n",
    "    custom_df = custom_df.rename(columns={'reference_caption': 'reference'})\n",
    "    \n",
    "    merged_df = pd.merge(\n",
    "        custom_df, \n",
    "        smolvlm_df, \n",
    "        on=['filename', 'occlusion_level'], \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    smolvlm_rows = []\n",
    "    custom_rows = []\n",
    "    \n",
    "    for _, row in merged_df.iterrows():\n",
    "        filename = row['filename']\n",
    "        occlusion_level = row['occlusion_level']\n",
    "        reference = row['reference']\n",
    "        \n",
    "        if pd.notna(row['smolvlm_caption']):\n",
    "            smolvlm_rows.append({\n",
    "                'image_id': filename,\n",
    "                'occlusion_level': occlusion_level,\n",
    "                'original_caption': reference,\n",
    "                'generated_caption': row['smolvlm_caption'],\n",
    "                'model_name': 'SmolVLM'\n",
    "            })\n",
    "        \n",
    "        custom_rows.append({\n",
    "            'image_id': filename,\n",
    "            'occlusion_level': occlusion_level,\n",
    "            'original_caption': reference,\n",
    "            'generated_caption': row['custom_caption'],\n",
    "            'model_name': 'Custom'\n",
    "        })\n",
    "    \n",
    "    all_rows = smolvlm_rows + custom_rows\n",
    "    processed_data = pd.DataFrame(all_rows)\n",
    "    \n",
    "    processed_data['occlusion_level'] = processed_data['occlusion_level'].astype(str)\n",
    "    \n",
    "    print(f\"Total processed data points: {len(processed_data)}\")\n",
    "    print(f\"SmolVLM data points: {len(smolvlm_rows)}\")\n",
    "    print(f\"Custom model data points: {len(custom_rows)}\")\n",
    "    \n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class: `CaptionDataset`\n",
    "\n",
    "#### **Purpose**:\n",
    "Prepares data for training/testing by tokenizing input text and assigning labels.\n",
    "\n",
    "#### **Inputs**:\n",
    "- `dataframe`: Data containing captions and occlusion levels.\n",
    "- `tokenizer`: Pre-trained tokenizer (e.g., BERT).\n",
    "- `max_length`: Maximum token length (default: 128).\n",
    "\n",
    "#### **Outputs**:\n",
    "- Returns tokenized input (`input_ids`, `attention_mask`) and label:\n",
    "  - `label = 0` for `SmolVLM`, `1` for `Custom`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T10:53:39.175776Z",
     "iopub.status.busy": "2025-04-14T10:53:39.175551Z",
     "iopub.status.idle": "2025-04-14T10:53:39.201987Z",
     "shell.execute_reply": "2025-04-14T10:53:39.201291Z",
     "shell.execute_reply.started": "2025-04-14T10:53:39.175758Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CaptionDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=128):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        \n",
    "        input_text = f\"{row['original_caption']} [SEP] {row['generated_caption']} [SEP] {row['occlusion_level']}\"\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            input_text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        label = 0 if row['model_name'] == 'SmolVLM' else 1\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class: `CaptionClassifier`\n",
    "\n",
    "#### **Purpose**:\n",
    "A BERT-based classifier for distinguishing between `SmolVLM` and `Custom` captions.\n",
    "\n",
    "#### **Architecture**:\n",
    "1. **Encoder**: Pre-trained BERT (`bert-base-uncased`).\n",
    "2. **Dropout**: Regularization with a 0.1 dropout rate.\n",
    "3. **Classifier**: Two fully connected layers with ReLU activation.\n",
    "\n",
    "#### **Forward Pass**:\n",
    "1. Extracts `pooler_output` from BERT.\n",
    "2. Applies dropout and passes through the classifier to generate logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T10:53:39.203165Z",
     "iopub.status.busy": "2025-04-14T10:53:39.202908Z",
     "iopub.status.idle": "2025-04-14T10:53:39.220798Z",
     "shell.execute_reply": "2025-04-14T10:53:39.220282Z",
     "shell.execute_reply.started": "2025-04-14T10:53:39.203139Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CaptionClassifier(nn.Module):\n",
    "    def __init__(self, pretrained_model_name='bert-base-uncased', num_classes=2):\n",
    "        super(CaptionClassifier, self).__init__()\n",
    "        \n",
    "        self.bert = BertModel.from_pretrained(pretrained_model_name)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.bert.config.hidden_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        \n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `train_classifier`\n",
    "\n",
    "#### **Purpose**:\n",
    "Trains the `CaptionClassifier` model using a given dataset.\n",
    "\n",
    "#### **Inputs**:\n",
    "- `model`: The classifier model.\n",
    "- `dataloader`: DataLoader for training data.\n",
    "- `optimizer`: Optimizer for updating model weights.\n",
    "- `criterion`: Loss function (e.g., CrossEntropyLoss).\n",
    "- `device`: Device to run the model (CPU/GPU).\n",
    "- `epochs`: Number of training epochs.\n",
    "\n",
    "#### **Outputs**:\n",
    "- Prints training progress and metrics for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T10:53:39.221703Z",
     "iopub.status.busy": "2025-04-14T10:53:39.221448Z",
     "iopub.status.idle": "2025-04-14T10:53:39.246130Z",
     "shell.execute_reply": "2025-04-14T10:53:39.245362Z",
     "shell.execute_reply.started": "2025-04-14T10:53:39.221676Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_classifier(model, dataloader, optimizer, criterion, device, epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        \n",
    "        progress_bar = tqdm(dataloader, desc=f\"Training\", leave=False)\n",
    "        \n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "            \n",
    "            progress_bar.set_postfix({'loss': loss.item(), 'accuracy': correct_predictions / total_predictions})\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "        epoch_accuracy = correct_predictions / total_predictions\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `evaluate_classifier`\n",
    "\n",
    "#### **Purpose**:\n",
    "Evaluates the `CaptionClassifier` model on a test dataset.\n",
    "\n",
    "#### **Inputs**:\n",
    "- `model`: The trained classifier model.\n",
    "- `dataloader`: DataLoader for evaluation data.\n",
    "- `device`: Device to run the model (CPU/GPU).\n",
    "\n",
    "#### **Outputs**:\n",
    "- Prints evaluation metrics (accuracy, precision, recall, F1 score).\n",
    "- Returns a dictionary of metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T10:53:39.248191Z",
     "iopub.status.busy": "2025-04-14T10:53:39.247961Z",
     "iopub.status.idle": "2025-04-14T10:53:39.270277Z",
     "shell.execute_reply": "2025-04-14T10:53:39.269680Z",
     "shell.execute_reply.started": "2025-04-14T10:53:39.248175Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_classifier(model, dataloader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            _, predictions = torch.max(outputs, dim=1)\n",
    "            \n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average='macro')\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `main`\n",
    "\n",
    "#### **Purpose**:\n",
    "This function runs the entire process: loading data, training the model, validating it, and testing its performance.\n",
    "\n",
    "#### **Steps**:\n",
    "1. **Load and Process Data**:\n",
    "   - Reads CSV files for `Custom` and `SmolVLM` models.\n",
    "   - Splits the data into training, validation, and test sets.\n",
    "   - Prepares datasets and dataloaders.\n",
    "\n",
    "2. **Train the Model**:\n",
    "   - Initializes the `CaptionClassifier`.\n",
    "   - Trains the model using the training data.\n",
    "   - Uses early stopping to avoid overfitting by monitoring validation F1 score.\n",
    "\n",
    "3. **Evaluate the Model**:\n",
    "   - Loads the best model saved during training.\n",
    "   - Tests the model on the test set and calculates metrics like accuracy, precision, recall, and F1 score.\n",
    "   - Saves the metrics and predictions to CSV files.\n",
    "\n",
    "4. **Analyze Performance**:\n",
    "   - Calculates accuracy for different occlusion levels.\n",
    "   - Creates a bar chart showing accuracy vs. occlusion level and saves it.\n",
    "\n",
    "#### **Outputs**:\n",
    "- Metrics saved in `part_c_metrics.csv`.\n",
    "- Predictions saved in `part_c_predictions.csv`.\n",
    "- Accuracy chart saved as `occlusion_level_performance.png`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T10:53:39.271258Z",
     "iopub.status.busy": "2025-04-14T10:53:39.271065Z",
     "iopub.status.idle": "2025-04-14T10:53:39.298384Z",
     "shell.execute_reply": "2025-04-14T10:53:39.297655Z",
     "shell.execute_reply.started": "2025-04-14T10:53:39.271243Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    custom_model_file = \"/kaggle/input/dl2partbresults/partB_custom.csv\"\n",
    "    smolvlm_file = \"/kaggle/input/dl2partbresults/output_smolvlm_partb.csv\"\n",
    "    \n",
    "    print(\"Loading and processing data...\")\n",
    "    processed_data = load_and_process_csv_data(custom_model_file, smolvlm_file)\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    image_ids = processed_data['image_id'].unique()\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(image_ids)\n",
    "    \n",
    "    n_images = len(image_ids)\n",
    "    train_size = int(0.7 * n_images)\n",
    "    val_size = int(0.1 * n_images)\n",
    "    \n",
    "    train_image_ids = image_ids[:train_size]\n",
    "    val_image_ids = image_ids[train_size:train_size+val_size]\n",
    "    test_image_ids = image_ids[train_size+val_size:]\n",
    "    \n",
    "    train_df = processed_data[processed_data['image_id'].isin(train_image_ids)]\n",
    "    val_df = processed_data[processed_data['image_id'].isin(val_image_ids)]\n",
    "    test_df = processed_data[processed_data['image_id'].isin(test_image_ids)]\n",
    "    \n",
    "    train_dataset = CaptionDataset(train_df, tokenizer)\n",
    "    val_dataset = CaptionDataset(val_df, tokenizer)\n",
    "    test_dataset = CaptionDataset(test_df, tokenizer)\n",
    "    \n",
    "    batch_size = 16\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    print(f\"Training set size: {len(train_dataset)}\")\n",
    "    print(f\"Validation set size: {len(val_dataset)}\")\n",
    "    print(f\"Test set size: {len(test_dataset)}\")\n",
    "    \n",
    "    train_labels = [train_dataset[i]['label'].item() for i in range(len(train_dataset))]\n",
    "    val_labels = [val_dataset[i]['label'].item() for i in range(len(val_dataset))]\n",
    "    test_labels = [test_dataset[i]['label'].item() for i in range(len(test_dataset))]\n",
    "    \n",
    "    print(f\"Training set label distribution: SmolVLM={train_labels.count(0)}, Custom={train_labels.count(1)}\")\n",
    "    print(f\"Validation set label distribution: SmolVLM={val_labels.count(0)}, Custom={val_labels.count(1)}\")\n",
    "    print(f\"Test set label distribution: SmolVLM={test_labels.count(0)}, Custom={test_labels.count(1)}\")\n",
    "    \n",
    "    model = CaptionClassifier().to(device)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    print(\"Training classifier...\")\n",
    "    train_classifier(model, train_dataloader, optimizer, criterion, device, epochs=3)\n",
    "    \n",
    "    best_val_f1 = 0\n",
    "    patience = 3\n",
    "    counter = 0\n",
    "    early_stopping_flag = False\n",
    "    \n",
    "    for epoch in range(7):\n",
    "        train_classifier(model, train_dataloader, optimizer, criterion, device, epochs=1)\n",
    "        \n",
    "        model.eval()\n",
    "        all_val_preds = []\n",
    "        all_val_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_dataloader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                _, predictions = torch.max(outputs, dim=1)\n",
    "                \n",
    "                all_val_preds.extend(predictions.cpu().numpy())\n",
    "                all_val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        _, _, val_f1, _ = precision_recall_fscore_support(all_val_labels, all_val_preds, average='macro')\n",
    "        print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
    "        \n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), 'best_classifier_model.pt')\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "                early_stopping_flag = True\n",
    "                break\n",
    "    \n",
    "    if early_stopping_flag or os.path.exists('best_classifier_model.pt'):\n",
    "        model.load_state_dict(torch.load('best_classifier_model.pt'))\n",
    "    \n",
    "    print(\"Evaluating classifier...\")\n",
    "    test_metrics = evaluate_classifier(model, test_dataloader, device)\n",
    "    \n",
    "    metrics_df = pd.DataFrame([test_metrics])\n",
    "    metrics_df.to_csv('part_c_metrics.csv', index=False)\n",
    "    \n",
    "    model.eval()\n",
    "    all_test_preds = []\n",
    "    all_test_labels = []\n",
    "    all_test_images = []\n",
    "    all_test_occlusions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, item in enumerate(test_dataset):\n",
    "            input_ids = item['input_ids'].unsqueeze(0).to(device)\n",
    "            attention_mask = item['attention_mask'].unsqueeze(0).to(device)\n",
    "            label = item['label'].item()\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, prediction = torch.max(outputs, dim=1)\n",
    "            \n",
    "            all_test_preds.append(prediction.item())\n",
    "            all_test_labels.append(label)\n",
    "            all_test_images.append(test_df.iloc[i]['image_id'])\n",
    "            all_test_occlusions.append(test_df.iloc[i]['occlusion_level'])\n",
    "    \n",
    "    predictions_df = pd.DataFrame({\n",
    "        'image_id': all_test_images,\n",
    "        'occlusion_level': all_test_occlusions,\n",
    "        'true_model': ['SmolVLM' if label == 0 else 'Custom' for label in all_test_labels],\n",
    "        'predicted_model': ['SmolVLM' if pred == 0 else 'Custom' for pred in all_test_preds],\n",
    "        'correct': [pred == label for pred, label in zip(all_test_preds, all_test_labels)]\n",
    "    })\n",
    "    \n",
    "    predictions_df.to_csv('part_c_predictions.csv', index=False)\n",
    "    \n",
    "    occlusion_performance = predictions_df.groupby('occlusion_level')['correct'].mean().reset_index()\n",
    "    occlusion_performance.columns = ['occlusion_level', 'accuracy']\n",
    "    print(\"\\nPerformance by occlusion level:\")\n",
    "    print(occlusion_performance)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='occlusion_level', y='accuracy', data=occlusion_performance)\n",
    "    plt.title('Classification Accuracy by Occlusion Level')\n",
    "    plt.xlabel('Occlusion Level (%)')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.savefig('occlusion_level_performance.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Part C completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T10:53:39.299363Z",
     "iopub.status.busy": "2025-04-14T10:53:39.299182Z",
     "iopub.status.idle": "2025-04-14T11:04:50.480192Z",
     "shell.execute_reply": "2025-04-14T11:04:50.479333Z",
     "shell.execute_reply.started": "2025-04-14T10:53:39.299341Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing data...\n",
      "Total processed data points: 5568\n",
      "SmolVLM data points: 2784\n",
      "Custom model data points: 2784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe985e1075b4622a7da8a1821603df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7d3f265a6a4272a8d13a01666f6ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4954c3ce9b9f4383b0835fc01c1e8d8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8012f890f0a74f2c90dcf866ab38aecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 3894\n",
      "Validation set size: 552\n",
      "Test set size: 1122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set label distribution: SmolVLM=1947, Custom=1947\n",
      "Validation set label distribution: SmolVLM=276, Custom=276\n",
      "Test set label distribution: SmolVLM=561, Custom=561\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168132e949744d1fb4a716d8bd8a5694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier...\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Loss: 0.2118, Accuracy: 0.9081\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 - Loss: 0.0468, Accuracy: 0.9800\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - Loss: 0.0424, Accuracy: 0.9756\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Loss: 0.0312, Accuracy: 0.9784\n",
      "Validation F1 Score: 0.9837\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Loss: 0.0264, Accuracy: 0.9802\n",
      "Validation F1 Score: 0.9837\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Loss: 0.0261, Accuracy: 0.9795\n",
      "Validation F1 Score: 0.9837\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Loss: 0.0259, Accuracy: 0.9813\n",
      "Validation F1 Score: 0.9837\n",
      "Early stopping triggered after 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/777706266.py:94: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_classifier_model.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 71/71 [00:08<00:00,  8.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9750\n",
      "Precision: 0.9762\n",
      "Recall: 0.9750\n",
      "F1 Score: 0.9750\n",
      "\n",
      "Performance by occlusion level:\n",
      "  occlusion_level  accuracy\n",
      "0              10  0.973262\n",
      "1              50  0.975936\n",
      "2              80  0.975936\n",
      "Part C completed successfully!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7124072,
     "sourceId": 11400810,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
